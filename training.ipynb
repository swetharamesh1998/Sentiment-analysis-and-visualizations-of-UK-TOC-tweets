{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d92ba68-f5e9-4e5e-9c11-bf3e38723b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sentiment140_df = pd.read_csv('sentiment140.csv', encoding='latin-1', names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "\n",
    "\n",
    "sentiment140_df = sentiment140_df[['target', 'text']]\n",
    "\n",
    "\n",
    "positive_tweets = sentiment140_df[sentiment140_df['target'] == 4].sample(n=15000, random_state=42)\n",
    "negative_tweets = sentiment140_df[sentiment140_df['target'] == 0].sample(n=15000, random_state=42)\n",
    "\n",
    "\n",
    "balanced_sentiment140_df = pd.concat([positive_tweets, negative_tweets])\n",
    "\n",
    "balanced_sentiment140_df = balanced_sentiment140_df.sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "balanced_sentiment140_df.to_csv('sentiment45k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f767b94-f46b-4ff4-9a71-41b640fd8d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7617063822696217\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2989\n",
      "           4       0.77      0.75      0.76      3012\n",
      "\n",
      "    accuracy                           0.76      6001\n",
      "   macro avg       0.76      0.76      0.76      6001\n",
      "weighted avg       0.76      0.76      0.76      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "sentiment140_df = pd.read_csv('sentiment45k.csv', encoding='latin-1', names=['target', 'text'])\n",
    "\n",
    "sentiment140_df = sentiment140_df[['target', 'text']]\n",
    "\n",
    "\n",
    "cleaned_tweets_df = pd.read_excel('cleaned_tweets.xlsx')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment140_df['text'], sentiment140_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cleaned_tweets_vectorized = vectorizer.transform(cleaned_tweets_df['Tweet'])\n",
    "predicted_sentiment = model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['predicted_sentiment'] = predicted_sentiment\n",
    "\n",
    "\n",
    "cleaned_tweets_df.to_excel('cleaned_tweets_with_sentiment_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1df152-3a15-4293-a249-3dde17f3e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7430428261956341\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76      2989\n",
      "           4       0.79      0.66      0.72      3012\n",
      "\n",
      "    accuracy                           0.74      6001\n",
      "   macro avg       0.75      0.74      0.74      6001\n",
      "weighted avg       0.75      0.74      0.74      6001\n",
      "\n",
      "SVM Accuracy: 0.7617063822696217\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      2989\n",
      "           4       0.77      0.75      0.76      3012\n",
      "\n",
      "    accuracy                           0.76      6001\n",
      "   macro avg       0.76      0.76      0.76      6001\n",
      "weighted avg       0.76      0.76      0.76      6001\n",
      "\n",
      "Logistic Regression Accuracy: 0.7632061323112814\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2989\n",
      "           4       0.77      0.75      0.76      3012\n",
      "\n",
      "    accuracy                           0.76      6001\n",
      "   macro avg       0.76      0.76      0.76      6001\n",
      "weighted avg       0.76      0.76      0.76      6001\n",
      "\n",
      "Random Forest Accuracy: 0.7453757707048825\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      2989\n",
      "           4       0.76      0.71      0.74      3012\n",
      "\n",
      "    accuracy                           0.75      6001\n",
      "   macro avg       0.75      0.75      0.75      6001\n",
      "weighted avg       0.75      0.75      0.75      6001\n",
      "\n",
      "Gradient Boosting Machine Accuracy: 0.714047658723546\n",
      "Gradient Boosting Machine Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69      2989\n",
      "           4       0.69      0.77      0.73      3012\n",
      "\n",
      "    accuracy                           0.71      6001\n",
      "   macro avg       0.72      0.71      0.71      6001\n",
      "weighted avg       0.72      0.71      0.71      6001\n",
      "\n",
      "Decision Tree Accuracy: 0.6720546575570738\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67      2989\n",
      "           4       0.67      0.68      0.67      3012\n",
      "\n",
      "    accuracy                           0.67      6001\n",
      "   macro avg       0.67      0.67      0.67      6001\n",
      "weighted avg       0.67      0.67      0.67      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentiment140_df = pd.read_csv('sentiment45k.csv', encoding='latin-1', names=['target', 'text'])\n",
    "sentiment140_df = sentiment140_df[['target', 'text']]\n",
    "tweets_df = pd.read_excel('sorted_tweets.xlsx')\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment140_df['text'], sentiment140_df['target'], test_size=0.2, random_state=42)\n",
    "# Vectorize \n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "nb_y_pred = nb_model.predict(X_test_vectorized)\n",
    "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_y_pred))\n",
    "\n",
    "#SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "y_pred = svm_model.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#  Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vectorized, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test_vectorized)\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, lr_y_pred))\n",
    "\n",
    "#  Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vectorized, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test_vectorized)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "#  Gradient Boosting Machine\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gbm_model.fit(X_train_vectorized, y_train)\n",
    "gbm_y_pred = gbm_model.predict(X_test_vectorized)\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_y_pred)\n",
    "print(\"Gradient Boosting Machine Accuracy:\", gbm_accuracy)\n",
    "print(\"Gradient Boosting Machine Classification Report:\")\n",
    "print(classification_report(y_test, gbm_y_pred))\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_vectorized, y_train)\n",
    "dt_y_pred = dt_model.predict(X_test_vectorized)\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_y_pred))\n",
    "# Predict sentiment for cleaned tweets\n",
    "cleaned_tweets_vectorized = vectorizer.transform(cleaned_tweets_df['Tweet'])\n",
    "\n",
    "# Naive Bayes\n",
    "nb_predicted_sentiment = nb_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['nb_predicted_sentiment'] = nb_predicted_sentiment\n",
    "\n",
    "#SVM\n",
    "svm_predicted_sentiment = svm_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['svm_predicted_sentiment'] = svm_predicted_sentiment\n",
    "\n",
    "# Logistic Regression\n",
    "lr_predicted_sentiment = lr_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['lr_predicted_sentiment'] = lr_predicted_sentiment\n",
    "\n",
    "# Random Forest\n",
    "rf_predicted_sentiment = rf_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['rf_predicted_sentiment'] = rf_predicted_sentiment\n",
    "\n",
    "# GBM\n",
    "gbm_predicted_sentiment = gbm_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['gbm_predicted_sentiment'] = gbm_predicted_sentiment\n",
    "\n",
    "#DT\n",
    "dt_predicted_sentiment = dt_model.predict(cleaned_tweets_vectorized)\n",
    "cleaned_tweets_df['dt_predicted_sentiment'] = dt_predicted_sentiment\n",
    "\n",
    "cleaned_tweets_df.to_excel('tweets_with_predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1edfa387-fd72-4e41-bca7-c393281525fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7617063822696217\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2989\n",
      "           4       0.77      0.76      0.76      3012\n",
      "\n",
      "    accuracy                           0.76      6001\n",
      "   macro avg       0.76      0.76      0.76      6001\n",
      "weighted avg       0.76      0.76      0.76      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "sentiment_df = pd.read_csv('sentiment45k.csv', encoding='latin-1', names=['target', 'text'])\n",
    "sentiment_df['target'] = sentiment_df['target']\n",
    "sentiment_df.dropna(subset=['text'], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_df['text'], sentiment_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "sentiment_df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vectorized, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test_vectorized)\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, lr_y_pred))\n",
    "\n",
    "tweets_df = pd.read_excel('sentiment_data_with_regions.xlsx')\n",
    "\n",
    "tweets_df.dropna(subset=['Tweet'], inplace=True)\n",
    "\n",
    "cleaned_tweets_vectorized = vectorizer.transform(tweets_df['Tweet'])\n",
    "\n",
    "predicted_sentiment = lr_model.predict(cleaned_tweets_vectorized)\n",
    "tweets_df['predicted_sentiment'] = predicted_sentiment\n",
    "\n",
    "tweets_df.to_excel('sentiment_data_with_predicted_sentiment.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a25b66e8-567f-4221-abc4-2f04ee1e4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "tweets_df = pd.read_excel('sentiment_data_with_predicted_sentiment.xlsx')\n",
    "\n",
    "tweets_df['predicted_sentiment'] = tweets_df['predicted_sentiment'].map({0: 'negative', 4: 'positive'})\n",
    "\n",
    "tweets_df.to_excel('sentiment_data_with_predicted_sentiment.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f793725-7878-4819-88f1-7b78c11667fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sweth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VADER: 0.6586\n",
      "Classification Report for VADER Sentiment Analysis:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.42      0.55     15000\n",
      "    Positive       0.61      0.90      0.72     15000\n",
      "\n",
      "    accuracy                           0.66     30000\n",
      "   macro avg       0.70      0.66      0.64     30000\n",
      "weighted avg       0.70      0.66      0.64     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "df = pd.read_csv('sentiment45k.csv')\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "df['vader_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "\n",
    "df['vader_sentiment'] = df['vader_score'].apply(lambda x: 4 if x >= 0 else 0)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(df['target'], df['vader_sentiment'])\n",
    "print(f\"Accuracy of VADER: {accuracy}\")\n",
    "\n",
    "\n",
    "report = classification_report(df['target'], df['vader_sentiment'], target_names=['Negative', 'Positive'])\n",
    "print(\"Classification Report for VADER Sentiment Analysis:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0eaf1d-3440-4b66-9832-fe3815216629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
